{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcd2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 45211\n",
      "Total Columns: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a4315_row0_col0, #T_a4315_row0_col1, #T_a4315_row0_col2, #T_a4315_row0_col3, #T_a4315_row0_col4, #T_a4315_row0_col5, #T_a4315_row1_col0, #T_a4315_row1_col1, #T_a4315_row1_col2, #T_a4315_row1_col3, #T_a4315_row1_col4, #T_a4315_row1_col5, #T_a4315_row2_col0, #T_a4315_row2_col1, #T_a4315_row2_col2, #T_a4315_row2_col3, #T_a4315_row2_col4, #T_a4315_row2_col5, #T_a4315_row3_col0, #T_a4315_row3_col1, #T_a4315_row3_col2, #T_a4315_row3_col3, #T_a4315_row3_col4, #T_a4315_row3_col5, #T_a4315_row4_col0, #T_a4315_row4_col1, #T_a4315_row4_col2, #T_a4315_row4_col3, #T_a4315_row4_col4, #T_a4315_row4_col5, #T_a4315_row5_col0, #T_a4315_row5_col1, #T_a4315_row5_col2, #T_a4315_row5_col3, #T_a4315_row5_col4, #T_a4315_row5_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a4315\">\n",
       "  <caption>Final Data Quality Report - All 6 Pillars (with Totals)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a4315_level0_col0\" class=\"col_heading level0 col0\" >Pillar</th>\n",
       "      <th id=\"T_a4315_level0_col1\" class=\"col_heading level0 col1\" >Column Name</th>\n",
       "      <th id=\"T_a4315_level0_col2\" class=\"col_heading level0 col2\" >Issue description</th>\n",
       "      <th id=\"T_a4315_level0_col3\" class=\"col_heading level0 col3\" >Row number</th>\n",
       "      <th id=\"T_a4315_level0_col4\" class=\"col_heading level0 col4\" >Issue Record Count</th>\n",
       "      <th id=\"T_a4315_level0_col5\" class=\"col_heading level0 col5\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a4315_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_a4315_row0_col1\" class=\"data row0 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_a4315_row0_col2\" class=\"data row0 col2\" >No accuracy issues found</td>\n",
       "      <td id=\"T_a4315_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a4315_row1_col0\" class=\"data row1 col0\" >Completeness</td>\n",
       "      <td id=\"T_a4315_row1_col1\" class=\"data row1 col1\" >All Columns</td>\n",
       "      <td id=\"T_a4315_row1_col2\" class=\"data row1 col2\" >No missing values found</td>\n",
       "      <td id=\"T_a4315_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a4315_row2_col0\" class=\"data row2 col0\" >Consistency</td>\n",
       "      <td id=\"T_a4315_row2_col1\" class=\"data row2 col1\" >day</td>\n",
       "      <td id=\"T_a4315_row2_col2\" class=\"data row2 col2\" >Values out of range 1-31</td>\n",
       "      <td id=\"T_a4315_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a4315_row3_col0\" class=\"data row3 col0\" >Integrity</td>\n",
       "      <td id=\"T_a4315_row3_col1\" class=\"data row3 col1\" >All Columns</td>\n",
       "      <td id=\"T_a4315_row3_col2\" class=\"data row3 col2\" >No integrity constraints defined</td>\n",
       "      <td id=\"T_a4315_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a4315_row4_col0\" class=\"data row4 col0\" >Timeliness</td>\n",
       "      <td id=\"T_a4315_row4_col1\" class=\"data row4 col1\" >Date Fields</td>\n",
       "      <td id=\"T_a4315_row4_col2\" class=\"data row4 col2\" >No timeliness data provided for check</td>\n",
       "      <td id=\"T_a4315_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row4_col5\" class=\"data row4 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4315_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a4315_row5_col0\" class=\"data row5 col0\" >Uniqueness</td>\n",
       "      <td id=\"T_a4315_row5_col1\" class=\"data row5 col1\" >All Columns</td>\n",
       "      <td id=\"T_a4315_row5_col2\" class=\"data row5 col2\" >Duplicate records</td>\n",
       "      <td id=\"T_a4315_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_a4315_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_a4315_row5_col5\" class=\"data row5 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2031d7b9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';')\n",
    "total_records = len(df)\n",
    "total_columns = len(df.columns)\n",
    "print(f\"Total Records: {total_records}\")\n",
    "print(f\"Total Columns: {total_columns}\")\n",
    "\n",
    "# Expected domains\n",
    "expected_domains = {\n",
    "    \n",
    "    'age': (18, 95),           # Based on your data max\n",
    "    'balance': (-8019, 102127),# Accepting current observed range\n",
    "    'day': (1, 31),            # Days of a month, already fine\n",
    "    'duration': (0, 5000),     # max is 4918, round to 5000\n",
    "    'campaign': (1, 100),      # Current max is 63, but keeping 100 is realistic\n",
    "    'pdays': (-1, 999),        # max is 871, -1 is valid, 999 is fine as upper limit\n",
    "    'previous': (0, 300),       # max is 275, rounding to 300 for flexibility\n",
    "    \n",
    "\n",
    "    'job': [\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\",\n",
    "            \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\",\n",
    "            \"retired\", \"technician\", \"services\"],\n",
    "\n",
    "    'marital': [\"married\", \"divorced\", \"single\"],\n",
    "    'education': [\"unknown\", \"secondary\", \"primary\", \"tertiary\"],\n",
    "    'default': [\"yes\", \"no\"],\n",
    "    'housing': [\"yes\", \"no\"],\n",
    "    'loan': [\"yes\", \"no\"],\n",
    "    'contact': [\"unknown\", \"telephone\", \"cellular\"],\n",
    "    'day': (1, 31),\n",
    "    'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\",\n",
    "              \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'poutcome': [\"unknown\", \"other\", \"failure\", \"success\"],\n",
    "    'y': [\"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "# Prepare Report List\n",
    "report = []\n",
    "\n",
    "def add_issue(pillar, column, description, rows):\n",
    "    count = len(rows) if rows else 0\n",
    "    percentage = (count / total_records) * 100\n",
    "    percentage_str = f\"{percentage:.2f}%\"\n",
    "    row_list = rows if rows else None\n",
    "    report.append({\n",
    "        'Pillar': pillar,\n",
    "        'Column Name': column,\n",
    "        'Issue description': description,\n",
    "        'Row number': row_list,\n",
    "        'Issue Record Count': count,\n",
    "        'Percentage': percentage_str\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# Completeness\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "if missing_cols:\n",
    "    rows = df[df[missing_cols].isnull().any(axis=1)].index.tolist()\n",
    "    add_issue('Completeness', ', '.join(missing_cols), 'Missing values', rows)\n",
    "else:\n",
    "    add_issue('Completeness', 'All Columns', 'No missing values found', [])\n",
    "\n",
    "# ----------------------------\n",
    "# Uniqueness\n",
    "duplicates = df[df.duplicated()].index.tolist()\n",
    "add_issue('Uniqueness', 'All Columns', 'Duplicate records', duplicates)\n",
    "\n",
    "# ----------------------------\n",
    "# Accuracy (Numeric vs Categorical)\n",
    "accuracy_found = False\n",
    "\n",
    "for col, valid_values in expected_domains.items():\n",
    "    if col in df.columns:\n",
    "        if isinstance(valid_values, tuple):\n",
    "            min_val, max_val = valid_values\n",
    "            invalid_rows = df[~df[col].between(min_val, max_val)].index.tolist()\n",
    "            if invalid_rows:\n",
    "                add_issue('Accuracy', col, f'Values out of range {min_val} - {max_val}', invalid_rows)\n",
    "                accuracy_found = True\n",
    "        else:\n",
    "            invalid_rows = df[~df[col].isin(valid_values)].index.tolist()\n",
    "            if invalid_rows:\n",
    "                add_issue('Accuracy', col, 'Values not in expected domain', invalid_rows)\n",
    "                accuracy_found = True\n",
    "\n",
    "if not accuracy_found:\n",
    "    add_issue('Accuracy', 'All relevant columns', 'No accuracy issues found', [])\n",
    "\n",
    "# ----------------------------\n",
    "# Consistency (Example rule for day)\n",
    "if 'day' in df.columns:\n",
    "    invalid_days = df[~df['day'].between(1, 31)].index.tolist()\n",
    "    add_issue('Consistency', 'day', 'Values out of range 1-31', invalid_days)\n",
    "else:\n",
    "    add_issue('Consistency', 'Relevant Columns', 'No consistency rule applied', [])\n",
    "\n",
    "# ----------------------------\n",
    "# Timeliness (No dates in data)\n",
    "add_issue('Timeliness', 'Date Fields', 'No timeliness data provided for check', [])\n",
    "\n",
    "# ----------------------------\n",
    "# Integrity (No defined integrity constraints in provided data)\n",
    "add_issue('Integrity', 'All Columns', 'No integrity constraints defined', [])\n",
    "\n",
    "# ----------------------------\n",
    "# Final Report\n",
    "dq_report = pd.DataFrame(report)\n",
    "dq_report = dq_report.sort_values(by='Pillar').reset_index(drop=True)\n",
    "\n",
    "from IPython.display import display\n",
    "display(dq_report.style.set_properties(**{'text-align': 'left'})\n",
    "        .set_caption(\"Final Data Quality Report - All 6 Pillars (with Totals)\"))\n",
    "\n",
    "# Optional CSV export\n",
    "# dq_report.to_csv('final_data_quality_report_with_totals.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd6f892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Min     Max         Mean\n",
      "age         18      95    40.936210\n",
      "balance  -8019  102127  1362.272058\n",
      "day          1      31    15.806419\n",
      "duration     0    4918   258.163080\n",
      "campaign     1      63     2.763841\n",
      "pdays       -1     871    40.197828\n",
      "previous     0     275     0.580323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate min, max, mean\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Min': numeric_cols.min(),\n",
    "    'Max': numeric_cols.max(),\n",
    "    'Mean': numeric_cols.mean()\n",
    "})\n",
    "\n",
    "# Display\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d9dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 45211\n",
      "Total Columns: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5e0ed_row0_col0, #T_5e0ed_row0_col1, #T_5e0ed_row0_col2, #T_5e0ed_row0_col3, #T_5e0ed_row0_col4, #T_5e0ed_row0_col5, #T_5e0ed_row1_col0, #T_5e0ed_row1_col1, #T_5e0ed_row1_col2, #T_5e0ed_row1_col3, #T_5e0ed_row1_col4, #T_5e0ed_row1_col5, #T_5e0ed_row2_col0, #T_5e0ed_row2_col1, #T_5e0ed_row2_col2, #T_5e0ed_row2_col3, #T_5e0ed_row2_col4, #T_5e0ed_row2_col5, #T_5e0ed_row3_col0, #T_5e0ed_row3_col1, #T_5e0ed_row3_col2, #T_5e0ed_row3_col3, #T_5e0ed_row3_col4, #T_5e0ed_row3_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e0ed\">\n",
       "  <caption>Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5e0ed_level0_col0\" class=\"col_heading level0 col0\" >Pillar</th>\n",
       "      <th id=\"T_5e0ed_level0_col1\" class=\"col_heading level0 col1\" >Column Name</th>\n",
       "      <th id=\"T_5e0ed_level0_col2\" class=\"col_heading level0 col2\" >Issue description</th>\n",
       "      <th id=\"T_5e0ed_level0_col3\" class=\"col_heading level0 col3\" >Row number</th>\n",
       "      <th id=\"T_5e0ed_level0_col4\" class=\"col_heading level0 col4\" >Issue Record Count</th>\n",
       "      <th id=\"T_5e0ed_level0_col5\" class=\"col_heading level0 col5\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e0ed_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5e0ed_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_5e0ed_row0_col1\" class=\"data row0 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_5e0ed_row0_col2\" class=\"data row0 col2\" >No accuracy issues found</td>\n",
       "      <td id=\"T_5e0ed_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_5e0ed_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_5e0ed_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e0ed_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5e0ed_row1_col0\" class=\"data row1 col0\" >Completeness</td>\n",
       "      <td id=\"T_5e0ed_row1_col1\" class=\"data row1 col1\" >All Columns</td>\n",
       "      <td id=\"T_5e0ed_row1_col2\" class=\"data row1 col2\" >No missing values found</td>\n",
       "      <td id=\"T_5e0ed_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_5e0ed_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_5e0ed_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e0ed_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5e0ed_row2_col0\" class=\"data row2 col0\" >Consistency</td>\n",
       "      <td id=\"T_5e0ed_row2_col1\" class=\"data row2 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_5e0ed_row2_col2\" class=\"data row2 col2\" >No consistency issues found</td>\n",
       "      <td id=\"T_5e0ed_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_5e0ed_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_5e0ed_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e0ed_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5e0ed_row3_col0\" class=\"data row3 col0\" >Uniqueness</td>\n",
       "      <td id=\"T_5e0ed_row3_col1\" class=\"data row3 col1\" >All Columns</td>\n",
       "      <td id=\"T_5e0ed_row3_col2\" class=\"data row3 col2\" >Duplicate records</td>\n",
       "      <td id=\"T_5e0ed_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_5e0ed_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_5e0ed_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20319dbaad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# Load Data (Suppress Dtype Warning)\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';', dtype=str)\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';')\n",
    "total_records = len(df)\n",
    "total_columns = len(df.columns)\n",
    "print(f\"Total Records: {total_records}\")\n",
    "print(f\"Total Columns: {total_columns}\")\n",
    "\n",
    "# --------------------------\n",
    "# Expected Domains\n",
    "expected_domains = {\n",
    "    'age': (18, 95),\n",
    "    'balance': (-8019, 102127),\n",
    "    'day': (1, 31),\n",
    "    'duration': (0, 5000),\n",
    "    'campaign': (1, 100),\n",
    "    'pdays': (-1, 999),\n",
    "    'previous': (0, 300),\n",
    "\n",
    "    'job': [\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\",\n",
    "            \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\",\n",
    "            \"retired\", \"technician\", \"services\"],\n",
    "    'marital': [\"married\", \"divorced\", \"single\"],\n",
    "    'education': [\"unknown\", \"secondary\", \"primary\", \"tertiary\"],\n",
    "    'default': [\"yes\", \"no\"],\n",
    "    'housing': [\"yes\", \"no\"],\n",
    "    'loan': [\"yes\", \"no\"],\n",
    "    'contact': [\"unknown\", \"telephone\", \"cellular\"],\n",
    "    'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\",\n",
    "              \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'poutcome': [\"unknown\", \"other\", \"failure\", \"success\"],\n",
    "    'y': [\"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "numeric_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# --------------------------\n",
    "# Reporting Utility\n",
    "report = []\n",
    "\n",
    "def add_issue(pillar, column, description, rows):\n",
    "    count = len(rows) if rows else 0\n",
    "    percentage = (count / total_records) * 100\n",
    "    if 0 < percentage < 0.01:\n",
    "        percentage_str = \"<0.01%\"\n",
    "    else:\n",
    "        percentage_str = f\"{percentage:.2f}%\"\n",
    "    row_list = rows if rows else None\n",
    "    report.append({\n",
    "        'Pillar': pillar,\n",
    "        'Column Name': column,\n",
    "        'Issue description': description,\n",
    "        'Row number': row_list,\n",
    "        'Issue Record Count': count,\n",
    "        'Percentage': percentage_str\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1 Completeness Check\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "if missing_cols:\n",
    "    rows = df[df[missing_cols].isnull().any(axis=1)].index.tolist()\n",
    "    add_issue('Completeness', ', '.join(missing_cols), 'Missing values', rows)\n",
    "else:\n",
    "    add_issue('Completeness', 'All Columns', 'No missing values found', [])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2 Uniqueness Check\n",
    "duplicates = df[df.duplicated()].index.tolist()\n",
    "add_issue('Uniqueness', 'All Columns', 'Duplicate records', duplicates)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3 Accuracy Checks\n",
    "\n",
    "accuracy_found = False\n",
    "\n",
    "# --- Data Type Validation & Numeric Range Checks (Fixed!)\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        # Convert to numeric safely\n",
    "        converted_col = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Identify rows where conversion failed (non-numeric values)\n",
    "        non_numeric_rows = df[pd.to_numeric(df[col], errors='coerce').isna() & df[col].notna()].index.tolist()\n",
    "        if non_numeric_rows:\n",
    "            add_issue('Accuracy', col, 'Non-numeric value found in numeric column', non_numeric_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "        # After conversion, check valid ranges only for numeric\n",
    "        valid_mask = converted_col.between(*expected_domains[col])\n",
    "        invalid_range_rows = df[~valid_mask & converted_col.notna()].index.tolist()\n",
    "        if invalid_range_rows:\n",
    "            add_issue('Accuracy', col, f'Values out of range {expected_domains[col]}', invalid_range_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "\n",
    "# --- Categorical Domains\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[~df[col].isin(expected_domains[col])].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Accuracy', col, 'Values not in expected domain list', invalid_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "if not accuracy_found:\n",
    "    add_issue('Accuracy', 'All relevant columns', 'No accuracy issues found', [])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4 Consistency Checks (Special Characters in Categorical Columns)\n",
    "special_characters = r'[^a-zA-Z0-9 ._-]'\n",
    "consistency_found = False\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[df[col].astype(str).apply(lambda x: bool(re.search(special_characters, x)))].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Consistency', col, 'Special characters not allowed in categorical fields', invalid_rows)\n",
    "            consistency_found = True\n",
    "\n",
    "if not consistency_found:\n",
    "    add_issue('Consistency', 'All relevant columns', 'No consistency issues found', [])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Final Report\n",
    "dq_report = pd.DataFrame(report)\n",
    "dq_report = dq_report.sort_values(by='Pillar').reset_index(drop=True)\n",
    "\n",
    "from IPython.display import display\n",
    "display(dq_report.style.set_properties(**{'text-align': 'left'})\n",
    "        .set_caption(\"Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fef1096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 45211\n",
      "Total Columns: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5281a_row0_col0, #T_5281a_row0_col1, #T_5281a_row0_col2, #T_5281a_row0_col3, #T_5281a_row0_col4, #T_5281a_row0_col5, #T_5281a_row1_col0, #T_5281a_row1_col1, #T_5281a_row1_col2, #T_5281a_row1_col3, #T_5281a_row1_col4, #T_5281a_row1_col5, #T_5281a_row2_col0, #T_5281a_row2_col1, #T_5281a_row2_col2, #T_5281a_row2_col3, #T_5281a_row2_col4, #T_5281a_row2_col5, #T_5281a_row3_col0, #T_5281a_row3_col1, #T_5281a_row3_col2, #T_5281a_row3_col3, #T_5281a_row3_col4, #T_5281a_row3_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5281a\">\n",
       "  <caption>Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5281a_level0_col0\" class=\"col_heading level0 col0\" >Pillar</th>\n",
       "      <th id=\"T_5281a_level0_col1\" class=\"col_heading level0 col1\" >Column Name</th>\n",
       "      <th id=\"T_5281a_level0_col2\" class=\"col_heading level0 col2\" >Issue description</th>\n",
       "      <th id=\"T_5281a_level0_col3\" class=\"col_heading level0 col3\" >Row number</th>\n",
       "      <th id=\"T_5281a_level0_col4\" class=\"col_heading level0 col4\" >Issue Record Count</th>\n",
       "      <th id=\"T_5281a_level0_col5\" class=\"col_heading level0 col5\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5281a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5281a_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_5281a_row0_col1\" class=\"data row0 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_5281a_row0_col2\" class=\"data row0 col2\" >No accuracy issues found</td>\n",
       "      <td id=\"T_5281a_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_5281a_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_5281a_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5281a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5281a_row1_col0\" class=\"data row1 col0\" >Completeness</td>\n",
       "      <td id=\"T_5281a_row1_col1\" class=\"data row1 col1\" >All Columns</td>\n",
       "      <td id=\"T_5281a_row1_col2\" class=\"data row1 col2\" >No missing values found</td>\n",
       "      <td id=\"T_5281a_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_5281a_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_5281a_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5281a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5281a_row2_col0\" class=\"data row2 col0\" >Consistency</td>\n",
       "      <td id=\"T_5281a_row2_col1\" class=\"data row2 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_5281a_row2_col2\" class=\"data row2 col2\" >No consistency issues found</td>\n",
       "      <td id=\"T_5281a_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_5281a_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_5281a_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5281a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5281a_row3_col0\" class=\"data row3 col0\" >Uniqueness</td>\n",
       "      <td id=\"T_5281a_row3_col1\" class=\"data row3 col1\" >All Columns</td>\n",
       "      <td id=\"T_5281a_row3_col2\" class=\"data row3 col2\" >Duplicate records</td>\n",
       "      <td id=\"T_5281a_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_5281a_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_5281a_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20319dbaad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# Load Data (Suppress Dtype Warning)\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';', dtype=str)\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';')\n",
    "total_records = len(df)\n",
    "total_columns = len(df.columns)\n",
    "print(f\"Total Records: {total_records}\")\n",
    "print(f\"Total Columns: {total_columns}\")\n",
    "\n",
    "# --------------------------\n",
    "# Expected Domains\n",
    "expected_domains = {\n",
    "    'age': (18, 95),\n",
    "    'balance': None,  # No range check on balance\n",
    "    'day': (1, 31),\n",
    "    'duration': (0, np.inf),\n",
    "    'campaign': (1, np.inf),\n",
    "    'pdays': (-1, 999),\n",
    "    'previous': (0, 300),\n",
    "\n",
    "    'job': [\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\",\n",
    "            \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\",\n",
    "            \"retired\", \"technician\", \"services\"],\n",
    "    'marital': [\"married\", \"divorced\", \"single\"],\n",
    "    'education': [\"unknown\", \"secondary\", \"primary\", \"tertiary\"],\n",
    "    'default': [\"yes\", \"no\"],\n",
    "    'housing': [\"yes\", \"no\"],\n",
    "    'loan': [\"yes\", \"no\"],\n",
    "    'contact': [\"unknown\", \"telephone\", \"cellular\"],\n",
    "    'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\",\n",
    "              \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'poutcome': [\"unknown\", \"other\", \"failure\", \"success\"],\n",
    "    'y': [\"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "numeric_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# --------------------------\n",
    "# Reporting Utility\n",
    "report = []\n",
    "\n",
    "def add_issue(pillar, column, description, rows):\n",
    "    count = len(rows) if rows else 0\n",
    "    percentage = (count / total_records) * 100\n",
    "    if 0 < percentage < 0.01:\n",
    "        percentage_str = \"<0.01%\"\n",
    "    else:\n",
    "        percentage_str = f\"{percentage:.2f}%\"\n",
    "    row_list = rows if rows else None\n",
    "    report.append({\n",
    "        'Pillar': pillar,\n",
    "        'Column Name': column,\n",
    "        'Issue description': description,\n",
    "        'Row number': row_list,\n",
    "        'Issue Record Count': count,\n",
    "        'Percentage': percentage_str\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1 Completeness Check\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "if missing_cols:\n",
    "    rows = df[df[missing_cols].isnull().any(axis=1)].index.tolist()\n",
    "    add_issue('Completeness', ', '.join(missing_cols), 'Missing values', rows)\n",
    "else:\n",
    "   add_issue('Completeness', 'All Columns', 'No missing values found', [])\n",
    "\n",
    "# --------------------------\n",
    "# Completeness: \"unknown\" as missing for categorical fields\n",
    "# unknown_as_missing_found = False\n",
    "# for col in categorical_columns:\n",
    "#     if col in df.columns:\n",
    "#         unknown_rows = df[df[col] == 'unknown'].index.tolist()\n",
    "#         if unknown_rows:\n",
    "#             add_issue('Completeness', col, '\"unknown\" treated as missing value', unknown_rows)\n",
    "#             unknown_as_missing_found = True\n",
    "\n",
    "# if not unknown_as_missing_found:\n",
    "#     add_issue('Completeness', 'All categorical columns', 'No \"unknown\" values found', [])\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2 Uniqueness Check\n",
    "duplicates = df[df.duplicated()].index.tolist()\n",
    "add_issue('Uniqueness', 'All Columns', 'Duplicate records', duplicates)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3 Accuracy Checks\n",
    "\n",
    "accuracy_found = False\n",
    "\n",
    "# --- Data Type Validation & Numeric Range Checks (Corrected as requested)\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        # Convert to numeric safely\n",
    "        converted_col = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Identify rows where conversion failed (non-numeric values)\n",
    "        non_numeric_rows = df[pd.to_numeric(df[col], errors='coerce').isna() & df[col].notna()].index.tolist()\n",
    "        if non_numeric_rows:\n",
    "            add_issue('Accuracy', col, 'Non-numeric value found in numeric column', non_numeric_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "        # Skip balance range check as per requirement\n",
    "        if col == 'balance':\n",
    "            continue\n",
    "\n",
    "        # After conversion, check valid ranges\n",
    "        expected_range = expected_domains[col]\n",
    "        if expected_range is not None:\n",
    "            valid_mask = converted_col.between(*expected_range)\n",
    "            invalid_range_rows = df[~valid_mask & converted_col.notna()].index.tolist()\n",
    "            if invalid_range_rows:\n",
    "                add_issue('Accuracy', col, f'Values out of range {expected_range}', invalid_range_rows)\n",
    "                accuracy_found = True\n",
    "\n",
    "\n",
    "# --- Categorical Domains\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[~df[col].isin(expected_domains[col])].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Accuracy', col, 'Values not in expected domain list', invalid_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "if not accuracy_found:\n",
    "    add_issue('Accuracy', 'All relevant columns', 'No accuracy issues found', [])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4 Consistency Checks (Special Characters in Categorical Columns)\n",
    "special_characters = r'[^a-zA-Z0-9 ._-]'\n",
    "consistency_found = False\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[df[col].astype(str).apply(lambda x: bool(re.search(special_characters, x)))].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Consistency', col, 'Special characters not allowed in categorical fields', invalid_rows)\n",
    "            consistency_found = True\n",
    "\n",
    "if not consistency_found:\n",
    "    add_issue('Consistency', 'All relevant columns', 'No consistency issues found', [])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Final Report\n",
    "dq_report = pd.DataFrame(report)\n",
    "dq_report = dq_report.sort_values(by='Pillar').reset_index(drop=True)\n",
    "\n",
    "from IPython.display import display\n",
    "display(dq_report.style.set_properties(**{'text-align': 'left'})\n",
    "        .set_caption(\"Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd1a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 45211\n",
      "Total Columns: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_31826_row0_col0, #T_31826_row0_col1, #T_31826_row0_col2, #T_31826_row0_col3, #T_31826_row0_col4, #T_31826_row0_col5, #T_31826_row1_col0, #T_31826_row1_col1, #T_31826_row1_col2, #T_31826_row1_col3, #T_31826_row1_col4, #T_31826_row1_col5, #T_31826_row2_col0, #T_31826_row2_col1, #T_31826_row2_col2, #T_31826_row2_col3, #T_31826_row2_col4, #T_31826_row2_col5, #T_31826_row3_col0, #T_31826_row3_col1, #T_31826_row3_col2, #T_31826_row3_col3, #T_31826_row3_col4, #T_31826_row3_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_31826\">\n",
       "  <caption>Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_31826_level0_col0\" class=\"col_heading level0 col0\" >Pillar</th>\n",
       "      <th id=\"T_31826_level0_col1\" class=\"col_heading level0 col1\" >Column Name</th>\n",
       "      <th id=\"T_31826_level0_col2\" class=\"col_heading level0 col2\" >Issue description</th>\n",
       "      <th id=\"T_31826_level0_col3\" class=\"col_heading level0 col3\" >Row number</th>\n",
       "      <th id=\"T_31826_level0_col4\" class=\"col_heading level0 col4\" >Issue Record Count</th>\n",
       "      <th id=\"T_31826_level0_col5\" class=\"col_heading level0 col5\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_31826_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_31826_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_31826_row0_col1\" class=\"data row0 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_31826_row0_col2\" class=\"data row0 col2\" >No accuracy issues found</td>\n",
       "      <td id=\"T_31826_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_31826_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_31826_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31826_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_31826_row1_col0\" class=\"data row1 col0\" >Completeness</td>\n",
       "      <td id=\"T_31826_row1_col1\" class=\"data row1 col1\" >All Columns</td>\n",
       "      <td id=\"T_31826_row1_col2\" class=\"data row1 col2\" >No missing values found</td>\n",
       "      <td id=\"T_31826_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_31826_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_31826_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31826_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_31826_row2_col0\" class=\"data row2 col0\" >Consistency</td>\n",
       "      <td id=\"T_31826_row2_col1\" class=\"data row2 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_31826_row2_col2\" class=\"data row2 col2\" >No consistency issues found</td>\n",
       "      <td id=\"T_31826_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_31826_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_31826_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31826_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_31826_row3_col0\" class=\"data row3 col0\" >Uniqueness</td>\n",
       "      <td id=\"T_31826_row3_col1\" class=\"data row3 col1\" >All Columns</td>\n",
       "      <td id=\"T_31826_row3_col2\" class=\"data row3 col2\" >Duplicate records</td>\n",
       "      <td id=\"T_31826_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_31826_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_31826_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20319dbaad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------------------\n",
    "# Load Data with Original CSV Row Numbers\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';', dtype=str)\n",
    "df.reset_index(inplace=True)\n",
    "df['CSV_Row_Number'] = df['index'] + 2  # CSV header is row 1, data starts at 2\n",
    "df.drop(columns='index', inplace=True)\n",
    "\n",
    "total_records = len(df)\n",
    "total_columns = len(df.columns)\n",
    "print(f\"Total Records: {total_records}\")\n",
    "print(f\"Total Columns: {total_columns}\")\n",
    "\n",
    "# --------------------------\n",
    "# Expected Domains\n",
    "expected_domains = {\n",
    "    'age': (18, 95),\n",
    "    'balance': None,\n",
    "    'day': (1, 31),\n",
    "    'duration': (0, np.inf),\n",
    "    'campaign': (1, np.inf),\n",
    "    'pdays': (-1, 999),\n",
    "    'previous': (0, 300),\n",
    "    'job': [\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\",\n",
    "            \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\",\n",
    "            \"retired\", \"technician\", \"services\"],\n",
    "    'marital': [\"married\", \"divorced\", \"single\"],\n",
    "    'education': [\"unknown\", \"secondary\", \"primary\", \"tertiary\"],\n",
    "    'default': [\"yes\", \"no\"],\n",
    "    'housing': [\"yes\", \"no\"],\n",
    "    'loan': [\"yes\", \"no\"],\n",
    "    'contact': [\"unknown\", \"telephone\", \"cellular\"],\n",
    "    'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\",\n",
    "              \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'poutcome': [\"unknown\", \"other\", \"failure\", \"success\"],\n",
    "    'y': [\"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "                       'contact', 'month', 'poutcome', 'y']\n",
    "numeric_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# --------------------------\n",
    "# Reporting Utility\n",
    "report = []\n",
    "\n",
    "def add_issue(pillar, column, description, rows):\n",
    "    count = len(rows) if rows else 0\n",
    "    percentage = (count / total_records) * 100\n",
    "    percentage_str = \"<0.01%\" if 0 < percentage < 0.01 else f\"{percentage:.2f}%\"\n",
    "    row_list = df.loc[rows, 'CSV_Row_Number'].tolist() if rows else None\n",
    "    report.append({\n",
    "        'Pillar': pillar,\n",
    "        'Column Name': column,\n",
    "        'Issue description': description,\n",
    "        'Row number': row_list,\n",
    "        'Issue Record Count': count,\n",
    "        'Percentage': percentage_str\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1 Completeness Check\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "if missing_cols:\n",
    "    rows = df[df[missing_cols].isnull().any(axis=1)].index.tolist()\n",
    "    add_issue('Completeness', ', '.join(missing_cols), 'Missing values', rows)\n",
    "else:\n",
    "    add_issue('Completeness', 'All Columns', 'No missing values found', [])\n",
    "\n",
    "# --------------------------\n",
    "# 2 Uniqueness Check\n",
    "duplicates = df[df.duplicated()].index.tolist()\n",
    "add_issue('Uniqueness', 'All Columns', 'Duplicate records', duplicates)\n",
    "\n",
    "# --------------------------\n",
    "# 3 Accuracy Checks\n",
    "accuracy_found = False\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        converted_col = pd.to_numeric(df[col], errors='coerce')\n",
    "        non_numeric_rows = df[pd.to_numeric(df[col], errors='coerce').isna() & df[col].notna()].index.tolist()\n",
    "        if non_numeric_rows:\n",
    "            add_issue('Accuracy', col, 'Non-numeric value found in numeric column', non_numeric_rows)\n",
    "            accuracy_found = True\n",
    "        if col == 'balance':\n",
    "            continue\n",
    "        expected_range = expected_domains[col]\n",
    "        if expected_range is not None:\n",
    "            valid_mask = converted_col.between(*expected_range)\n",
    "            invalid_range_rows = df[~valid_mask & converted_col.notna()].index.tolist()\n",
    "            if invalid_range_rows:\n",
    "                add_issue('Accuracy', col, f'Values out of range {expected_range}', invalid_range_rows)\n",
    "                accuracy_found = True\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[~df[col].isin(expected_domains[col])].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Accuracy', col, 'Values not in expected domain list', invalid_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "if not accuracy_found:\n",
    "    add_issue('Accuracy', 'All relevant columns', 'No accuracy issues found', [])\n",
    "\n",
    "# --------------------------\n",
    "# 4 Consistency Checks (Special Characters in Categorical Columns)\n",
    "special_characters = r'[^a-zA-Z0-9 ._-]'\n",
    "consistency_found = False\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[df[col].astype(str).apply(lambda x: bool(re.search(special_characters, x)))].index.tolist()\n",
    "        if invalid_rows:\n",
    "            add_issue('Consistency', col, 'Special characters not allowed in categorical fields', invalid_rows)\n",
    "            consistency_found = True\n",
    "\n",
    "if not consistency_found:\n",
    "    add_issue('Consistency', 'All relevant columns', 'No consistency issues found', [])\n",
    "\n",
    "# --------------------------\n",
    "# Final Report\n",
    "dq_report = pd.DataFrame(report)\n",
    "dq_report = dq_report.sort_values(by='Pillar').reset_index(drop=True)\n",
    "\n",
    "display(dq_report.style.set_properties(**{'text-align': 'left'})\n",
    "        .set_caption(\"Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6b0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 45211\n",
      "Total Columns: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c16de_row0_col0, #T_c16de_row0_col1, #T_c16de_row0_col2, #T_c16de_row0_col3, #T_c16de_row0_col4, #T_c16de_row0_col5, #T_c16de_row1_col0, #T_c16de_row1_col1, #T_c16de_row1_col2, #T_c16de_row1_col3, #T_c16de_row1_col4, #T_c16de_row1_col5, #T_c16de_row2_col0, #T_c16de_row2_col1, #T_c16de_row2_col2, #T_c16de_row2_col3, #T_c16de_row2_col4, #T_c16de_row2_col5, #T_c16de_row3_col0, #T_c16de_row3_col1, #T_c16de_row3_col2, #T_c16de_row3_col3, #T_c16de_row3_col4, #T_c16de_row3_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c16de\">\n",
       "  <caption>Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c16de_level0_col0\" class=\"col_heading level0 col0\" >Pillar</th>\n",
       "      <th id=\"T_c16de_level0_col1\" class=\"col_heading level0 col1\" >Column Name</th>\n",
       "      <th id=\"T_c16de_level0_col2\" class=\"col_heading level0 col2\" >Issue description</th>\n",
       "      <th id=\"T_c16de_level0_col3\" class=\"col_heading level0 col3\" >Row number</th>\n",
       "      <th id=\"T_c16de_level0_col4\" class=\"col_heading level0 col4\" >Issue Record Count</th>\n",
       "      <th id=\"T_c16de_level0_col5\" class=\"col_heading level0 col5\" >Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c16de_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c16de_row0_col0\" class=\"data row0 col0\" >Accuracy</td>\n",
       "      <td id=\"T_c16de_row0_col1\" class=\"data row0 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_c16de_row0_col2\" class=\"data row0 col2\" >No accuracy issues found</td>\n",
       "      <td id=\"T_c16de_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_c16de_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_c16de_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c16de_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c16de_row1_col0\" class=\"data row1 col0\" >Completeness</td>\n",
       "      <td id=\"T_c16de_row1_col1\" class=\"data row1 col1\" >All Columns</td>\n",
       "      <td id=\"T_c16de_row1_col2\" class=\"data row1 col2\" >No missing values found</td>\n",
       "      <td id=\"T_c16de_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_c16de_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_c16de_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c16de_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c16de_row2_col0\" class=\"data row2 col0\" >Consistency</td>\n",
       "      <td id=\"T_c16de_row2_col1\" class=\"data row2 col1\" >All relevant columns</td>\n",
       "      <td id=\"T_c16de_row2_col2\" class=\"data row2 col2\" >No consistency issues found</td>\n",
       "      <td id=\"T_c16de_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_c16de_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_c16de_row2_col5\" class=\"data row2 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c16de_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c16de_row3_col0\" class=\"data row3 col0\" >Uniqueness</td>\n",
       "      <td id=\"T_c16de_row3_col1\" class=\"data row3 col1\" >All Columns</td>\n",
       "      <td id=\"T_c16de_row3_col2\" class=\"data row3 col2\" >Duplicate records</td>\n",
       "      <td id=\"T_c16de_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_c16de_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_c16de_row3_col5\" class=\"data row3 col5\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20319dbaad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No issues found.\n",
      "\n",
      " Data Quality Report saved to:\n",
      "D:/Projects/bank/Data_Quality_Report_20250721_124112.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# Load Data (Read only ONCE)\n",
    "df = pd.read_csv('D:/Projects/bank/bank-full.csv', sep=';', dtype=str)\n",
    "\n",
    "# Preserve original CSV row numbers aligned to Excel (Header = Row 1)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'OriginalRowNumber_ZeroBased'}, inplace=True)\n",
    "df['CSV_Row_Number'] = df['OriginalRowNumber_ZeroBased'] + 2  # Header + 1-based counting\n",
    "\n",
    "total_records = len(df)\n",
    "total_columns = len(df.columns)\n",
    "print(f\"Total Records: {total_records}\")\n",
    "print(f\"Total Columns: {total_columns}\")\n",
    "# --------------------------\n",
    "# Expected Domains\n",
    "expected_domains = {\n",
    "    'age': (18, 95),\n",
    "    'balance': None,\n",
    "    'day': (1, 31),\n",
    "    'duration': (0, np.inf),\n",
    "    'campaign': (1, np.inf),\n",
    "    'pdays': (-1, 999),\n",
    "    'previous': (0, 300),\n",
    "    'job': [\"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\",\n",
    "            \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\",\n",
    "            \"retired\", \"technician\", \"services\"],\n",
    "    'marital': [\"married\", \"divorced\", \"single\"],\n",
    "    'education': [\"unknown\", \"secondary\", \"primary\", \"tertiary\"],\n",
    "    'default': [\"yes\", \"no\"],\n",
    "    'housing': [\"yes\", \"no\"],\n",
    "    'loan': [\"yes\", \"no\"],\n",
    "    'contact': [\"unknown\", \"telephone\", \"cellular\"],\n",
    "    'month': [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\",\n",
    "              \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\n",
    "    'poutcome': [\"unknown\", \"other\", \"failure\", \"success\"],\n",
    "    'y': [\"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "numeric_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# --------------------------\n",
    "# Reporting Utility\n",
    "report = []\n",
    "detailed_report = []\n",
    "\n",
    "def add_issue(pillar, column, description, rows):\n",
    "    adjusted_rows = df.loc[rows, 'CSV_Row_Number'].tolist() if rows else None\n",
    "    count = len(rows) if rows else 0\n",
    "    percentage = (count / total_records) * 100\n",
    "    percentage_str = \"<0.01%\" if 0 < percentage < 0.01 else f\"{percentage:.2f}%\"\n",
    "    report.append({\n",
    "        'Pillar': pillar,\n",
    "        'Column Name': column,\n",
    "        'Issue description': description,\n",
    "        'Row number': adjusted_rows,\n",
    "        'Issue Record Count': count,\n",
    "        'Percentage': percentage_str\n",
    "    })\n",
    "\n",
    "# --------------------------\n",
    "# Completeness Check\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "if missing_cols:\n",
    "    rows = df[df[missing_cols].isnull().any(axis=1)].index.tolist()\n",
    "    for r in rows:\n",
    "        detailed_report.append({\n",
    "            'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "            'Pillar': 'Completeness',\n",
    "            'Column': ', '.join(missing_cols),\n",
    "            'Actual Value': 'Missing',\n",
    "            'Expected': 'Non-missing value'\n",
    "        })\n",
    "    add_issue('Completeness', ', '.join(missing_cols), 'Missing values', rows)\n",
    "else:\n",
    "    add_issue('Completeness', 'All Columns', 'No missing values found', [])\n",
    "\n",
    "# --------------------------\n",
    "# Uniqueness Check\n",
    "duplicates = df[df.duplicated()].index.tolist()\n",
    "for r in duplicates:\n",
    "    detailed_report.append({\n",
    "        'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "        'Pillar': 'Uniqueness',\n",
    "        'Column': 'All Columns',\n",
    "        'Actual Value': 'Duplicate Row',\n",
    "        'Expected': 'Unique Row'\n",
    "    })\n",
    "add_issue('Uniqueness', 'All Columns', 'Duplicate records', duplicates)\n",
    "\n",
    "# --------------------------\n",
    "# Accuracy Checks\n",
    "accuracy_found = False\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        converted_col = pd.to_numeric(df[col], errors='coerce')\n",
    "        non_numeric_rows = df[pd.to_numeric(df[col], errors='coerce').isna() & df[col].notna()].index.tolist()\n",
    "        if non_numeric_rows:\n",
    "            for r in non_numeric_rows:\n",
    "                detailed_report.append({\n",
    "                    'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "                    'Pillar': 'Accuracy',\n",
    "                    'Column': col,\n",
    "                    'Actual Value': df.loc[r, col],\n",
    "                    'Expected': 'Numeric'\n",
    "                })\n",
    "            add_issue('Accuracy', col, 'Non-numeric value found in numeric column', non_numeric_rows)\n",
    "            accuracy_found = True\n",
    "        if col == 'balance':\n",
    "            continue\n",
    "        expected_range = expected_domains[col]\n",
    "        if expected_range is not None:\n",
    "            valid_mask = converted_col.between(*expected_range)\n",
    "            invalid_range_rows = df[~valid_mask & converted_col.notna()].index.tolist()\n",
    "            if invalid_range_rows:\n",
    "                for r in invalid_range_rows:\n",
    "                    detailed_report.append({\n",
    "                        'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "                        'Pillar': 'Accuracy',\n",
    "                        'Column': col,\n",
    "                        'Actual Value': df.loc[r, col],\n",
    "                        'Expected': f\"{expected_range[0]} to {expected_range[1]}\"\n",
    "                    })\n",
    "                add_issue('Accuracy', col, f'Values out of range {expected_range}', invalid_range_rows)\n",
    "                accuracy_found = True\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[~df[col].isin(expected_domains[col])].index.tolist()\n",
    "        if invalid_rows:\n",
    "            for r in invalid_rows:\n",
    "                detailed_report.append({\n",
    "                    'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "                    'Pillar': 'Accuracy',\n",
    "                    'Column': col,\n",
    "                    'Actual Value': df.loc[r, col],\n",
    "                    'Expected': f\"{expected_domains[col]}\"\n",
    "                })\n",
    "            add_issue('Accuracy', col, 'Values not in expected domain list', invalid_rows)\n",
    "            accuracy_found = True\n",
    "\n",
    "if not accuracy_found:\n",
    "    add_issue('Accuracy', 'All relevant columns', 'No accuracy issues found', [])\n",
    "\n",
    "# --------------------------\n",
    "# Consistency Checks (Special Characters in Categorical Columns)\n",
    "special_characters = r'[^a-zA-Z0-9 ._-]'\n",
    "consistency_found = False\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        invalid_rows = df[df[col].astype(str).apply(lambda x: bool(re.search(special_characters, x)))].index.tolist()\n",
    "        if invalid_rows:\n",
    "            for r in invalid_rows:\n",
    "                detailed_report.append({\n",
    "                    'Row': df.loc[r, 'CSV_Row_Number'],\n",
    "                    'Pillar': 'Consistency',\n",
    "                    'Column': col,\n",
    "                    'Actual Value': df.loc[r, col],\n",
    "                    'Expected': 'No special characters allowed'\n",
    "                })\n",
    "            add_issue('Consistency', col, 'Special characters not allowed in categorical fields', invalid_rows)\n",
    "            consistency_found = True\n",
    "\n",
    "if not consistency_found:\n",
    "    add_issue('Consistency', 'All relevant columns', 'No consistency issues found', [])\n",
    "\n",
    "# --------------------------\n",
    "# --------------------------\n",
    "# Create DataFrames\n",
    "dq_report = pd.DataFrame(report).sort_values(by='Pillar').reset_index(drop=True)\n",
    "\n",
    "detailed_report_df = pd.DataFrame(detailed_report)\n",
    "if not detailed_report_df.empty:\n",
    "    detailed_report_df = detailed_report_df.sort_values(by='Row').reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Display Summary\n",
    "from IPython.display import display\n",
    "display(dq_report.style.set_properties(**{'text-align': 'left'})\n",
    "        .set_caption(\"Data Quality Report (Accuracy, Completeness, Consistency, Uniqueness)\"))\n",
    "\n",
    "if not detailed_report_df.empty:\n",
    "    display(detailed_report_df.style.set_properties(**{'text-align': 'left'})\n",
    "            .set_caption(\"Detailed Expected vs Actual Values Report (With Pillars)\"))\n",
    "else:\n",
    "    print(\"No issues found.\")\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from datetime import datetime\n",
    "\n",
    "# --------------------------\n",
    "# --------------------------\n",
    "# Convert lists to strings for Excel\n",
    "if 'Row number' in dq_report.columns:\n",
    "    dq_report['Row number'] = dq_report['Row number'].apply(\n",
    "        lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x\n",
    "    )\n",
    "\n",
    "# --------------------------\n",
    "# Export to Excel\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from datetime import datetime\n",
    "\n",
    "output_file = f\"D:/Projects/bank/Data_Quality_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "wb.remove(wb.active)  # remove default sheet\n",
    "\n",
    "# --------------------------\n",
    "# Write Summary Report\n",
    "ws1 = wb.create_sheet(title=\"Summary_Report\")\n",
    "for r_idx, row in enumerate(dataframe_to_rows(dq_report, index=False, header=True), 1):\n",
    "    ws1.append(row)\n",
    "    for c_idx, cell in enumerate(ws1[r_idx], 1):\n",
    "        if r_idx == 1:\n",
    "            cell.font = Font(bold=True)\n",
    "            ws1.auto_filter.ref = ws1.dimensions\n",
    "        cell.alignment = Alignment(wrap_text=True, vertical='top')\n",
    "\n",
    "for col in ws1.columns:\n",
    "    max_length = max(len(str(cell.value)) if cell.value is not None else 0 for cell in col)\n",
    "    ws1.column_dimensions[col[0].column_letter].width = max_length + 2\n",
    "\n",
    "# --------------------------\n",
    "# Write Detailed Report\n",
    "ws2 = wb.create_sheet(title=\"Detailed_Report\")\n",
    "if not detailed_report_df.empty:\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(detailed_report_df, index=False, header=True), 1):\n",
    "        ws2.append(row)\n",
    "        for c_idx, cell in enumerate(ws2[r_idx], 1):\n",
    "            if r_idx == 1:\n",
    "                cell.font = Font(bold=True)\n",
    "                ws2.auto_filter.ref = ws2.dimensions\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical='top')\n",
    "\n",
    "    for col in ws2.columns:\n",
    "        max_length = max(len(str(cell.value)) if cell.value is not None else 0 for cell in col)\n",
    "        ws2.column_dimensions[col[0].column_letter].width = max_length + 2\n",
    "\n",
    "# --------------------------\n",
    "# Save Workbook\n",
    "wb.save(output_file)\n",
    "print(f\"\\n Data Quality Report saved to:\\n{output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
